import {
  TokenType,
  Token,
  Lexer,
  Keyword,
  LexerOptions,
} from "../lexer"

const ReservedSet = new Set<TokenType>([
  Keyword.ADD,
	Keyword.ALL,
	Keyword.ALTER,
	Keyword.AND,
	Keyword.ANY,
	Keyword.AS,
	Keyword.ASC,
	Keyword.AUTHORIZATION,
	Keyword.BACKUP,
	Keyword.BEGIN,
	Keyword.BETWEEN,
	Keyword.BREAK,
	Keyword.BROWSE,
	Keyword.BULK,
	Keyword.BY,
	Keyword.CASCADE,
	Keyword.CASE,
	Keyword.CHECK,
	Keyword.CHECKPOINT,
	Keyword.CLOSE,
	Keyword.CLUSTERED,
	Keyword.COALESCE,
	Keyword.COLLATE,
	Keyword.COLUMN,
	Keyword.COMMIT,
	Keyword.COMPUTE,
	Keyword.CONSTRAINT,
	Keyword.CONTAINS,
	Keyword.CONTAINSTABLE,
	Keyword.CONTINUE,
	Keyword.CONVERT,
	Keyword.CREATE,
	Keyword.CROSS,
	Keyword.CURRENT,
	Keyword.CURRENT_DATE,
	Keyword.CURRENT_TIME,
	Keyword.CURRENT_TIMESTAMP,
	Keyword.CURRENT_USER,
	Keyword.CURSOR,
	Keyword.DATABASE,
	Keyword.DBCC,
	Keyword.DEALLOCATE,
	Keyword.DECLARE,
	Keyword.DEFAULT,
	Keyword.DELETE,
	Keyword.DENY,
	Keyword.DESC,
	Keyword.DISK,
	Keyword.DISTINCT,
	Keyword.DISTRIBUTED,
	Keyword.DOUBLE,
	Keyword.DROP,
	Keyword.DUMP,
	Keyword.ELSE,
	Keyword.END,
	Keyword.ERRLVL,
	Keyword.ESCAPE,
	Keyword.EXCEPT,
	Keyword.EXEC,
	Keyword.EXECUTE,
	Keyword.EXISTS,
	Keyword.EXIT,
	Keyword.EXTERNAL,
	Keyword.FETCH,
	Keyword.FILE,
	Keyword.FILLFACTOR,
	Keyword.FOR,
	Keyword.FOREIGN,
	Keyword.FREETEXT,
	Keyword.FREETEXTTABLE,
	Keyword.FROM,
	Keyword.FULL,
	Keyword.FUNCTION,
	Keyword.GOTO,
	Keyword.GRANT,
	Keyword.GROUP,
	Keyword.HAVING,
	Keyword.HOLDLOCK,
	Keyword.IDENTITY,
	Keyword.IDENTITYCOL,
	Keyword.IDENTITY_INSERT,
	Keyword.IF,
	Keyword.IN,
	Keyword.INDEX,
	Keyword.INNER,
	Keyword.INSERT,
	Keyword.INTERSECT,
	Keyword.INTO,
	Keyword.IS,
	Keyword.JOIN,
	Keyword.KEY,
	Keyword.KILL,
	Keyword.LEFT,
	Keyword.LIKE,
	Keyword.LINENO,
	Keyword.LOAD,
	Keyword.MERGE,
	Keyword.NATIONAL,
	Keyword.NOCHECK,
	Keyword.NONCLUSTERED,
	Keyword.NOT,
	Keyword.NULL,
	Keyword.NULLIF,
	Keyword.OF,
	Keyword.OFF,
	Keyword.OFFSETS,
	Keyword.ON,
	Keyword.OPEN,
	Keyword.OPENDATASOURCE,
	Keyword.OPENQUERY,
	Keyword.OPENROWSET,
	Keyword.OPENXML,
	Keyword.OPTION,
	Keyword.OR,
	Keyword.ORDER,
	Keyword.OUTER,
	Keyword.OVER,
	Keyword.PERCENT,
	Keyword.PIVOT,
	Keyword.PLAN,
	Keyword.PRECISION,
	Keyword.PRIMARY,
	Keyword.PRINT,
	Keyword.PROC,
	Keyword.PROCEDURE,
	Keyword.PUBLIC,
	Keyword.RAISERROR,
	Keyword.READ,
	Keyword.READTEXT,
	Keyword.RECONFIGURE,
	Keyword.REFERENCES,
	Keyword.REPLICATION,
	Keyword.RESTORE,
	Keyword.RESTRICT,
	Keyword.RETURN,
	Keyword.REVERT,
	Keyword.REVOKE,
	Keyword.RIGHT,
	Keyword.ROLLBACK,
	Keyword.ROWCOUNT,
	Keyword.ROWGUIDCOL,
	Keyword.RULE,
	Keyword.SAVE,
	Keyword.SCHEMA,
	Keyword.SECURITYAUDIT,
	Keyword.SELECT,
	Keyword.SEMANTICKEYPHRASETABLE,
	Keyword.SEMANTICSIMILARITYDETAILSTABLE,
	Keyword.SEMANTICSIMILARITYTABLE,
	Keyword.SESSION_USER,
	Keyword.SET,
	Keyword.SETUSER,
	Keyword.SHUTDOWN,
	Keyword.SOME,
	Keyword.STATISTICS,
	Keyword.SYSTEM_USER,
	Keyword.TABLE,
	Keyword.TABLESAMPLE,
	Keyword.TEXTSIZE,
	Keyword.THEN,
	Keyword.TO,
	Keyword.TOP,
	Keyword.TRAN,
	Keyword.TRANSACTION,
	Keyword.TRIGGER,
	Keyword.TRUNCATE,
	Keyword.TRY_CONVERT,
	Keyword.TSEQUAL,
	Keyword.UNION,
	Keyword.UNIQUE,
	Keyword.UNPIVOT,
	Keyword.UPDATE,
	Keyword.UPDATETEXT,
	Keyword.USE,
	Keyword.USER,
	Keyword.VALUES,
	Keyword.VARYING,
	Keyword.VIEW,
	Keyword.WAITFOR,
	Keyword.WHEN,
	Keyword.WHERE,
	Keyword.WHILE,
	Keyword.WITH,
	Keyword.WITHIN,
	Keyword.WRITETEXT,
])

export declare type MssqlLexerOptions = LexerOptions & {
}

export class MssqlLexer extends Lexer {
  constructor(
    options: { [key: string]: any } = {}
  ) {
    super("mssql", [
      { type: TokenType.Delimiter, re: /^[ \t]*go(?=[ \t-]|$)/imy, separator: true },
      { type: TokenType.SemiColon, re: /;/y, separator: true },
      { type: TokenType.WhiteSpace, re: /[ \f\t\v\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff]+/y, skip: true },
      { type: TokenType.LineBreak, re: /\r?\n/y, skip: true, separator: true },
      { type: TokenType.BlockComment, re: /\/\*(?:(?!\/\*|\*\/).)*\*\//sy, skip: true },
      { type: TokenType.LineComment, re: /--.*/y, skip: true },
      { type: TokenType.LeftParen, re: /\(/y, separator: true },
      { type: TokenType.RightParen, re: /\)/y, separator: true },
      { type: TokenType.Comma, re: /,/y, separator: true },
      { type: TokenType.Number, re: /0[xX][0-9a-fA-F]+|((0|[1-9][0-9]*)(\.[0-9]+)?|(\.[0-9]+))([eE][+-]?[0-9]+)?/y },
      { type: TokenType.Dot, re: /\./y, separator: true },
      { type: TokenType.String, re: /'([^']|'')*'/y },
      { type: TokenType.QuotedIdentifier, re: /"([^"]|"")*"/y },
      { type: TokenType.BindVariable, re: /:[a-zA-Z\u8000-\uFFEE\uFFF0-\uFFFD\uFFFF][a-zA-Z0-9_$#\u8000-\uFFEE\uFFF0-\uFFFD\uFFFF]*/y },
      { type: TokenType.Variable, re: /@[a-zA-Z\u8000-\uFFEE\uFFF0-\uFFFD\uFFFF][a-zA-Z0-9_$#\u8000-\uFFEE\uFFF0-\uFFFD\uFFFF]*/y },
      { type: TokenType.Identifier, re: /(@@)?[a-zA-Z\u8000-\uFFEE\uFFF0-\uFFFD\uFFFF][a-zA-Z0-9_$#\u8000-\uFFEE\uFFF0-\uFFFD\uFFFF]*/y },
      { type: TokenType.Operator, re: /\|\||<<|>>|<>|::|[=<>!*/%^&|+-]=?|![<>]|[~]/y, separator: true },
      { type: TokenType.Error, re: /./y, separator: true },
    ], options)
  }

  protected processToken(state: Record<string, any>, token: Token) {
    if (token.type === TokenType.Identifier) {
      const keyword = Keyword[token.text.toUpperCase()]
      if (keyword) {
        token.keyword = keyword
        if (ReservedSet.has(keyword)) {
          token.type = keyword
        }
      }
    }
    return token
  }
}